{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birth Weight Prediction Using Model Selection and Regularized regression \n",
    "\n",
    "## Data set \n",
    "The file kaiser.csv contains a subset of data from the Child Health and Development Studies, which investigate a range of topics. One study considered all pregnancies between 1960 and 1967 among women in the Kaiser Foundation Health Plan in the San Francisco East Bay area. Here, we look at the predictor of birth weight of babies, measured in pounds, as well as the occurrence of complications in the first 3 month. \n",
    "\n",
    "The data frame stored in kaiser.csv contains the variables: \n",
    "- age:          Age of the mom at time of birth\n",
    "- smoke:        Is the mom a smoker / non-smoker? \n",
    "- hospital:     Which hospital was the birth at? Oakland, SanFrancisco, WalnutCreek, SanJose, and Richmond.\n",
    "- gestation:    Gestation period (length of pregnancy) [days]\n",
    "- parity:       1: child the first born 0: Child has older siblings \n",
    "- weight:       Weight of the baby [pounds].  \n",
    "- complication: Was there a complication within the first 3 month of pregnancy (0: No 1:Yes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.optimize as so\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multRegPredict(b,D,xname):\n",
    "    \"\"\"Prediction function for multipel regression \n",
    "\n",
    "    Args:\n",
    "        b (nd.array): Array of regression coefficients - first is intercept \n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        xname (list): List of strings with names of explanatory variables  \n",
    "\n",
    "    Returns:\n",
    "        yp (nd.array): Predicted y - values \n",
    "    \"\"\"\n",
    "    yp=np.ones(len(D.index))*b[0]        # Intercept \n",
    "    for i in range(len(xname)):          \n",
    "        yp=yp+D[xname[i]]*b[i+1]         # Add each regression value \n",
    "    return yp \n",
    "\n",
    "def multRegLossRSS(b,D,y,xname):\n",
    "    \"\"\"Loss function for OLS multiple regression \n",
    "\n",
    "    Args:\n",
    "        b (nd.array): Array of regression coefficients - first is intercept \n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        y (ndarray): Dependent variable \n",
    "        xname (list): List of strings with names of explanatory variables  \n",
    "\n",
    "    Returns:\n",
    "        rss: Current loss\n",
    "        grad: gradient of loss function in respect to parameters  \n",
    "    \"\"\"\n",
    "    predY = multRegPredict(b,D,xname)\n",
    "    res = y-predY\n",
    "    rss = sum(res**2)\n",
    "    grad=np.zeros(len(b))\n",
    "    grad[0]=-2*np.sum(res)\n",
    "    for i in range(len(xname)):\n",
    "        grad[i+1]=-2*np.sum(D[xname[i]]*res)\n",
    "    return (rss,grad)\n",
    "\n",
    "def multRegFit(D,y,xname=[],figure=0,b0=[]):\n",
    "    \"\"\"Fits a multiple regression loss function \n",
    "\n",
    "    Args:\n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        y (ndarray): Dependent variable \n",
    "        xname (list): List of strings with names of explanatory variables  \n",
    "        figure (int): Plot figure? Defaults to 0.\n",
    "        b0 (np.ndarray). Initial guess for the parameter vector\n",
    "\n",
    "    Returns:\n",
    "        R2: Fitted R2 value \n",
    "        b: Fitted \n",
    "    \"\"\"\n",
    "    k=len(xname)+1\n",
    "    if (len(b0)!=k):\n",
    "        b0=np.zeros((k,))\n",
    "    RES = so.minimize(multRegLossRSS,b0,args=(D,y,xname),jac=True)\n",
    "    b=RES.x # Results\n",
    "    res = y-np.mean(y)\n",
    "    TSS = sum(res**2)\n",
    "    RSS,deriv = multRegLossRSS(b,D,y,xname)\n",
    "    R2 = 1-RSS/TSS \n",
    "    if (k==2 and figure==1):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ax.scatter(D[xname[0]],y)\n",
    "        xRange=[min(D[xname[0]]),max(D[xname[0]])]\n",
    "        xp=np.arange(xRange[0],xRange[1],(xRange[1]-xRange[0])/50)\n",
    "        yp=b[0]+b[1]*xp\n",
    "        ax.plot(xp,yp,'r-')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    return (R2,b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Multiple regression with discrete variables \n",
    "Create a dummy variable for Smoker / Non-smoker. Set the value for “Smoker” to 1 and for “Non-smoker” to 0. Estimate a regression model with the dummy variable as a regressor *and birth weight as the response variable.* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv('kaiser.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['smokeDummy'] = np.double(D['smoke'] == 'smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept is 7.69\n",
      "The slope is -1.21 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2, b = multRegFit(D,D['weight'],['smokeDummy'],figure=1,b0=[])\n",
    "plt.xlabel('smoke dummy variable')\n",
    "plt.ylabel('birth weight')\n",
    "print(f'The intercept is {b[0]:.2f}')\n",
    "print(f'The slope is {b[1]:.2f} ' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 1*. Shows the scatter plot of birth weight of babies with smoking mothers (1) and non-smoking moms (0). The red line is the regression line."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b0 (the intercept) is the mean of the non-smoking group (y = b[0] + b[1] * 0) and b[1] is the difference between the means of smokers and non-smokers (y = b[0] + b[1] * 1). Since b[1] is a negative value, the mean birth weight of babies of smoker group is lower than the mean of the non-smoker group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 \n",
    "Make a boxplot of hospital on the x-axis and birthweight on the y-axis (see HW2 for an example). Which hospital has the lowest overall birth weight?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='hospital', ylabel='weight'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=D.hospital,y=D.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 2*. Boxplot of birth weight of babies grouped by the hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/7lqgfrln5738xc_hktty2sb00000gp/T/ipykernel_34763/406678211.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  D.groupby('hospital').mean()['weight']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hospital\n",
       "Oakland         7.441426\n",
       "Richmond        7.313273\n",
       "SanFrancisco    7.667122\n",
       "SanJose         7.544500\n",
       "WalnutCreek     7.645780\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calucate the mean weight for each hospital\n",
    "D.groupby('hospital').mean()['weight']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Richmond has the lowest average birth weight. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3  \n",
    "Create a set of 4 dummy variables that together code the hospital. Set Walnut Creek to be your comparison group. Run a multiple regression model with the 4 dummy variables as explanatory variables. Report the interecept and slope values. What do the intercept and slope values mean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['hospOAK'] = np.double(D.hospital=='Oakland')\n",
    "D['hospSFO'] = np.double(D.hospital=='SanFrancisco')\n",
    "D['hospSJO'] = np.double(D.hospital=='SanJose')\n",
    "D['hospRIM'] = np.double(D.hospital=='Richmond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:7.646\n",
      "B:-0.204\n",
      "B:0.021\n",
      "B:-0.101\n",
      "B:-0.333\n"
     ]
    }
   ],
   "source": [
    "r2,b=multRegFit(D,D.weight,['hospOAK','hospSFO','hospSJO','hospRIM'])\n",
    "print(f\"B:{b[0]:3.3f}\")\n",
    "print(f\"B:{b[1]:3.3f}\")\n",
    "print(f\"B:{b[2]:3.3f}\")\n",
    "print(f\"B:{b[3]:3.3f}\")\n",
    "print(f\"B:{b[4]:3.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The incept is 7.429, which is the average weight for WalnutCreek<br> \n",
    "The slope for Oakland is -0.204, which means that the birth weight of babies in Oakland is 0.2 pounds lower than in WC <br>\n",
    "The slope for SFO is 0.021, which means that the birth weight of babies in SF is 0.021 pounds higher than in WC<br>\n",
    "The slope for SJO is -0.101, which means that the birth weight of babies in San Jose is 0.101 lower than in WC<br>\n",
    "The slope for Richmond is -0.33, which means that the birth weight of babies in Richmond is 0.33 pounds lower than in WC<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Model selection for multiple regression  \n",
    "### Question 2.1 \n",
    "Write a version of the crossvalidation function that does K-fold crossvalidation and works specifically with multRegFit as the fitting function. \n",
    "\n",
    "KfoldCVmultReg(D,y,xname,K=20,fitfcn=multRegFit,param={},predictfcn=multRegPredict):\n",
    "- D: Data Frame with explanatory variables  \n",
    "- y: response variable \n",
    "- xname: List of explanatory variables\n",
    "- K: Number of crossvalidation folds\n",
    "\n",
    "For dividing the data up in K pieces, you can use the following trick to assign a partition index to each of the data-points:\n",
    "```\n",
    "#N = number of data points \n",
    "#K = number of test sets (folds)\n",
    "ind = np.arange(N)\n",
    "ind = np.floor(ind/N*K)\n",
    "```\n",
    "\n",
    "\n",
    "The code should compute and return the predictive (crossvalidated) $R^2$ (R2cv) and the fitted $R^2$ (R2). \n",
    "It should use the entries in the Dictionary to pass them to the function using `fitfcn(D,y,xname,**param)`\n",
    "Run 20-fold crossvalidation on the multiple regression model, with birth weight as the response variable and \n",
    "\n",
    "- age of the mother \n",
    "- smoker (dummy coded) \n",
    "- birth occurred in Oakland? \n",
    "- gestation \n",
    "\n",
    "as explanatory variables. \n",
    "Report R2cv and R2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KfoldCVmultReg(D,y,xname,K=20):\n",
    "    \"\"\"K-fold Crossvalidation for multiple regression\"\"\"\n",
    "    N = len(y) #Number of observations\n",
    "    yp= np.zeros(N)\n",
    "\n",
    "    # Make an index vector with K folds\n",
    "    ind = np.arange(N)\n",
    "    ind = np.floor(ind/N*K)\n",
    "    \n",
    "    # Get overall model fit \n",
    "    R2,b_all=multRegFit(D,y,xname)\n",
    "\n",
    "    # Loop over the crossvalidation folds \n",
    "    for i in range(K):\n",
    "        r,b=multRegFit(D[ind!=i],y[ind!=i],xname,b0=b_all)\n",
    "        yp[ind==i]=multRegPredict(b,D[ind==i],xname)\n",
    "        \n",
    "    # Calculate crossvalidated model fit \n",
    "    TSS  = sum((y-y.mean())**2)\n",
    "    RSScv = sum((y-yp)**2)\n",
    "    R2cv = 1-RSScv/TSS\n",
    "    return R2cv,R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.3503\n",
      "Crossvalidated R2:0.2882\n"
     ]
    }
   ],
   "source": [
    "R2cv,R2 = KfoldCVmultReg(D,D.weight,['age','smokeDummy','gestation','parity'])\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> R2 is 0.3503, and cv R2 is 0.2882. So overall, we are able to predict 28.82% of the variance "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2 \n",
    "Using the R2cv from the 20-fold crossvalidation, determine the best predictive model for birthweight using the following candidate variables \n",
    "\n",
    "- age of mom\n",
    "- smoker (dummy coded) \n",
    "- gestation \n",
    "- parity \n",
    "\n",
    "Start with the R2cv for the full model (Question 2.1) and use **backwards** step-wise regression to find the best model (the model that increases R2cv the most). Show all steps of your selection procedure. Report the formula of your best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.3423\n",
      "Crossvalidated R2:0.2950\n"
     ]
    }
   ],
   "source": [
    "# Dropping Age \n",
    "R2cv,R2 = KfoldCVmultReg(D,D.weight,['smokeDummy','gestation','parity'])\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.2244\n",
      "Crossvalidated R2:0.1626\n"
     ]
    }
   ],
   "source": [
    "# Dropping Smoke Dummy\n",
    "R2cv,R2 = KfoldCVmultReg(D,D.weight,['age','gestation','parity'])\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.1917\n",
      "Crossvalidated R2:0.1282\n"
     ]
    }
   ],
   "source": [
    "# Dropping gestation    \n",
    "R2cv,R2 = KfoldCVmultReg(D,D.weight,['age','smokeDummy','parity'])\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.3503\n",
      "Crossvalidated R2:0.2936\n"
     ]
    }
   ],
   "source": [
    "# Dropping parity\n",
    "R2cv,R2 = KfoldCVmultReg(D,D.weight,['age','smokeDummy','gestation'])\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The R2cv increases most when dropping age as an explanatory variables. So we drop age and proceed with trying to drop another variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.2216\n",
      "Crossvalidated R2:0.1757\n"
     ]
    }
   ],
   "source": [
    "# Dropping Smoke Dummy\n",
    "R2cv,R2 = KfoldCVmultReg(D,D.weight,['gestation','parity'])\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.0067\n",
      "Crossvalidated R2:-0.0606\n"
     ]
    }
   ],
   "source": [
    "# Dropping gestation\n",
    "R2cv,R2 = KfoldCVmultReg(D,D.weight,['age','parity'])\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.3403\n",
      "Crossvalidated R2:0.3014\n"
     ]
    }
   ],
   "source": [
    "# Dropping parity   \n",
    "R2cv,R2 = KfoldCVmultReg(D,D.weight,['smokeDummy','gestation'])\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Parity improves the cross-validated R2 most. \n",
    "Dropping either of these terms now decreases R2cv quite dramatically - so \n",
    "\n",
    "weight = b_0 + b_1 * smokeDummy + b_2 * gestation \n",
    "\n",
    "is our best model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement regularilzed regression to build a better predictive model \n",
    "In this task you will implement regularized regression to try to build a better predictive model for the birthweight of data. \n",
    "Like in Task 2, we will consider the following explanatory variables:\n",
    "\n",
    "- age of the mother \n",
    "- smoker (dummy coded) \n",
    "- birth occurred in Oakland? \n",
    "- gestation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1: Z-standardize the regressors \n",
    "Write a function `zstandardize`, which takes as an input a pandas series or ndarray \n",
    "and returns a z-standardized version of the data \n",
    "\n",
    "Use the function to z-standardize the columns age,gestation,parity, and smokeDummy. \n",
    "\n",
    "Create new columns in the data frame called ageZ,gestationZ,parityZ, and smokeDummyZ.\n",
    "\n",
    "Check that the mean of the new variables in very close to and the std very close to 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 7.915890165577366e-16\n",
      "Std: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Z-standardize the data\n",
    "def zstandardize(d):\n",
    "    d = (d-d.mean())/d.std()\n",
    "    return d\n",
    "    \n",
    "D['ageZ'] = zstandardize(D.age)\n",
    "D['gestationZ'] = zstandardize(D.gestation)\n",
    "D['parityZ'] = zstandardize(D.parity)\n",
    "D['smokeDummyZ'] = zstandardize(D.smokeDummy)\n",
    "\n",
    "print(f'Mean: {D.ageZ.mean()}')\n",
    "print(f'Std: {D.ageZ.std()}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2 Implement Ridge regression (L2 regularized regression) \n",
    "\n",
    "To implement ridge regression you need to modify two functions, the most important being the loss function. \n",
    "Make a copy of the function `multRegLossRSS` from assigment 10. \n",
    "Rename it to `ridgeLoss`. Give the function an additional input parameter, namely alpha. Give this a default value of 1.0. \n",
    "\n",
    "Overall the function should take the following input arguments:\n",
    "\n",
    "    Args:\n",
    "        b (nd.array): Array of regression coefficients - first is intercept \n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        y (ndarray): Dependent variable \n",
    "        xname (list): List of strings with names of explanatory variables\n",
    "        alpha (float): Regularization parameter \n",
    "\n",
    "    Returns:\n",
    "        loss: Current loss\n",
    "        grad: gradient of loss function in respect to parameters  \n",
    "\n",
    "\n",
    "`so.minimize(ridgeLoss,b0,args=(D,y,xname,alpha),jac=True)`\n",
    "\n",
    "You need to take care when you calculate R2 of the fit - Since ridgeLoss does not return the \n",
    "residual-sum-of-squares, you need to use the appropriate function to calculate the RSS.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgeLoss(b,D,y,xname,alpha=1.0):\n",
    "    \"\"\"Loss function for Ridge regression \n",
    "\n",
    "    Args:\n",
    "        b (nd.array): Array of regression coefficients - first is intercept \n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        y (ndarray): Dependent variable \n",
    "        xname (list): List of strings with names of explanatory variables  \n",
    "        alpha (float): Ridge regression parameter\n",
    "    Returns:\n",
    "        rss: Current loss\n",
    "        grad: gradient of loss function in respect to parameters  \n",
    "    \"\"\"\n",
    "    predY = multRegPredict(b,D,xname)\n",
    "    res = y-predY\n",
    "    rss = sum(res**2)+alpha*sum(b[1:]**2)\n",
    "    grad=np.zeros(len(b))\n",
    "    grad[0]=-2*np.sum(res)\n",
    "    for i in range(len(xname)):\n",
    "        grad[i+1]=-2*np.sum(D[xname[i]]*res)+2*alpha*b[i+1]\n",
    "    return (rss,grad)\n",
    "\n",
    "def ridgeFit(D,y,xname,figure=0,b0=[],alpha=1.0):\n",
    "    \"\"\"Fits a multiple regression loss function \n",
    "\n",
    "    Args:\n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        y (ndarray): Dependent variable \n",
    "        xname (list): List of strings with names of explanatory variables  \n",
    "        figure (int): Plot figure? Defaults to 0.\n",
    "        b0 (np.ndarray). Initial guess for the parameter vector\n",
    "        alpha (float): Ridge regression parameter\n",
    "    Returns:\n",
    "        R2: Fitted R2 value \n",
    "        b: Fitted \n",
    "    \"\"\"\n",
    "    k=len(xname)+1\n",
    "    if (len(b0)!=k):\n",
    "        b0=np.zeros((k,))\n",
    "    RES = so.minimize(ridgeLoss,b0,args=(D,y,xname,alpha),jac=True)\n",
    "    b=RES.x # Results\n",
    "    res = y-np.mean(y)\n",
    "    TSS = sum(res**2)\n",
    "    RSS,deriv = multRegLossRSS(b,D,y,xname)\n",
    "    R2 = 1-RSS/TSS \n",
    "    if (k==2 and figure==1):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ax.scatter(D[xname[0]],y)\n",
    "        xRange=[min(D[xname[0]]),max(D[xname[0]])]\n",
    "        xp=np.arange(xRange[0],xRange[1],(xRange[1]-xRange[0])/50)\n",
    "        yp=b[0]+b[1]*xp\n",
    "        ax.plot(xp,yp,'r-')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    return (R2,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0\n",
      "R2: 0.3503\n",
      "alpha=8\n",
      "R2: 0.3488\n"
     ]
    }
   ],
   "source": [
    "R2_0,b_0 = ridgeFit(D,D.weight,['ageZ','smokeDummyZ','gestationZ','parityZ'],alpha=0.0)\n",
    "R2_1,b_1 = ridgeFit(D,D.weight,['ageZ','smokeDummyZ','gestationZ','parityZ'],alpha=8.0)\n",
    "\n",
    "print('alpha=0')\n",
    "print(f'R2: {R2_0:.4f}')\n",
    "\n",
    "print('alpha=8')\n",
    "print(f'R2: {R2_1:.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted R2 value reduces when we add regularization to the model. The R2 for `alpha=0` is identical to normal regression - because we set the regularization to zero, so it has no effect. *BTW: this is also a good test if your functions work correctly!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0\n",
      "[ 7.495e+00 -1.040e-01 -3.830e-01  4.340e-01  4.000e-03]\n",
      "alpha=8\n",
      "[ 7.495e+00 -9.400e-02 -3.580e-01  4.050e-01  3.000e-03]\n"
     ]
    }
   ],
   "source": [
    "print('alpha=0')\n",
    "print(b_0.round(3))\n",
    "print('alpha=8')\n",
    "print(b_1.round(3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept regressor (`b[0]`) did not change, as it was not regularized. However, all other regression coefficients are now closer to zero. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3: Crossvalidate Ridge regression \n",
    "Copy your function `KfoldCVmultReg` from Question 2.1, rename it to `KfoldCVridge`, and modify it to work with Ridge regression. \n",
    "That means it needs to take an additional input parameter `alpha` that it passes on to the fitting function. \n",
    "\n",
    "To calculate the R2 and R2cv for the model of `weight` using the explanatory variables `['ageZ','smokeDummyZ','gestationZ','parityZ']`. Like in question 3.2, use the standardized versions of the variables and try both the setting `alpha=0` and `alpha=8`. \n",
    "\n",
    "How to the R2 and R2cv values compare between the two settings of alpha? Do you get better predictive performance than the reduced model that you found using feature selection ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KfoldCVridge(D,y,xname,K=20,alpha=1.0):\n",
    "    \"\"\"K-fold Crossvalidation for multiple regression\"\"\"\n",
    "    N = len(y) #Number of observations\n",
    "    yp= np.zeros(N)\n",
    "\n",
    "    # Make an index vector with K folds\n",
    "    ind = np.arange(N)\n",
    "    ind = np.floor(ind/N*K)\n",
    "    \n",
    "    # Get overall model fit \n",
    "    R2,b_all=ridgeFit(D,y,xname,alpha=alpha)\n",
    "\n",
    "    # Loop over the crossvalidation folds \n",
    "    for i in range(K):\n",
    "        r,b=ridgeFit(D[ind!=i],y[ind!=i],xname,b0=b_all,alpha=alpha)\n",
    "        yp[ind==i]=multRegPredict(b,D[ind==i],xname)\n",
    "        \n",
    "    # Calculate crossvalidated model fit \n",
    "    TSS  = sum((y-y.mean())**2)\n",
    "    RSScv = sum((y-yp)**2)\n",
    "    R2cv = 1-RSScv/TSS\n",
    "    return R2cv,R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.3503\n",
      "Crossvalidated R2:0.2882\n"
     ]
    }
   ],
   "source": [
    "R2cv,R2 = KfoldCVridge(D,D.weight,['ageZ','smokeDummyZ','gestationZ','parityZ'],alpha=0)\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted R2:0.3487\n",
      "Crossvalidated R2:0.2950\n"
     ]
    }
   ],
   "source": [
    "R2cv,R2 = KfoldCVridge(D,D.weight,['ageZ','smokeDummyZ','gestationZ'],alpha=8)\n",
    "print(f\"Fitted R2:{R2:.4f}\")\n",
    "print(f\"Crossvalidated R2:{R2cv:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in Question 3.2. the fitted R2 becomes smaller for higher regularization parameter, because we do not minimize RSS anymore. \n",
    "\n",
    "In contrast, cross-validated R2 increases when regularizing the model. However the regularized model is not quite as good as the one that we found in question 2.2 using backwards stepwise regression. \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Use logistic regression to predict complications \n",
    "Create and test a logistic regression model that predicts the presence of a complication in the first three month (0: no complication, 1: complication). \n",
    "\n",
    "\n",
    "### Question 4.1: Improving your logistic regression model code\n",
    "Improve your code for logisitic regression in two ways: \n",
    "\n",
    "1. prevent log(0) errors by making sure that your predicted value never is smaller than 1e-20 or larger than 1-1e-20. (tip you can use the numpy function `clip`)\n",
    "\n",
    "2. Let logisticRegFit take an additional input parameter, telling it whether it should plot a figure or not (figure=1) \n",
    "\n",
    "3. Let logisticRegFit take an additional input parameter, specifying the starting value for the parameters (b_init=[]). If b_init is empty, the function should start with a vector off all zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegPredict(b,D,xname):\n",
    "    yp=np.ones(len(D.index))*b[0]       # Start out with the intercept  \n",
    "    for i in range(len(xname)):\n",
    "        yp=yp+D[xname[i]]*b[i+1]        # Add the prediction of each regressor seperately \n",
    "    p = np.exp(yp)/(1+np.exp(yp))\n",
    "    p = p.clip(1e-12,1-(1e-12))\n",
    "    return p \n",
    "    \n",
    "def logisticRegLoss(b,D,y,xname):\n",
    "    p = logisticRegPredict(b,D,xname)\n",
    "    cost = -y*np.log(p)-(1-y)*np.log(1-p)\n",
    "    N=len(xname)\n",
    "    grad=np.zeros(N+1)\n",
    "    res = y-p\n",
    "    grad[0]=-sum(res)\n",
    "    for i in range(N):\n",
    "        grad[i+1]=-np.sum(D[xname[i]]*res)         # Add each regressor \n",
    "    return (cost.sum(),grad)\n",
    "    \n",
    "def logisticRegFit(D,y,xname,figure=0,b_init=[]):\n",
    "    k=len(xname)+1\n",
    "    if (len(b_init)!=k):\n",
    "        b_init=np.zeros(k)\n",
    "    RES = so.minimize(logisticRegLoss,b_init,args=(D,y,xname),jac=True)\n",
    "    b = RES.x\n",
    "    ll = -RES.fun # Negative function value is the log likelihood \n",
    "    p = logisticRegPredict(b,D,xname)\n",
    "    if (k==2 & figure==1):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ax.scatter(D[xname[0]],y)\n",
    "        xRange=[min(D[xname[0]]),max(D[xname[0]])]\n",
    "        xp=np.arange(xRange[0],xRange[1],(xRange[1]-xRange[0])/50)\n",
    "        yp=b[0]+b[1]*xp\n",
    "        pp=np.exp(yp)/(1+np.exp(yp))\n",
    "        ax.plot(xp,pp,'r-')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    return (ll,b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.2: Crossvalidation of logistic models\n",
    "Modify the KfoldCVmultReg function to make it work for logistic regression. As before, use K-fold crossvalidation. The main changes are that \n",
    "- you need to use logisticRegFit and logisticRegPredict as fitfcn and predictfcn respectively. \n",
    "- To save time, initialize each optimization with from the parameters that you found on the entire data by setting `b_init` \n",
    "- instead of the crossvalidated R2, your function should return the crossvalidated log-likelihood and non-crossvalidated log-likelihood. \n",
    "\n",
    "Using your function, calculate the the difference in crossvalidated log-likelihood for the model that predicts complications with an intercept only (b0) and a model that predicts complications with an intercept and smokeDummy. \n",
    "From the difference, report the Bayes-Factor between the two models. What do you conclude? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KfoldCVlogisticReg(D,y,xname,K=20,fitfcn=logisticRegFit,predictfcn=logisticRegPredict):\n",
    "    N = len(y) #Number of observations\n",
    "    yp= np.zeros(N)\n",
    "    ind = np.arange(N)\n",
    "    ind = np.floor(ind/N*K)\n",
    "    \n",
    "    # Get overall model fit \n",
    "    LL,b_all=fitfcn(D,y,xname,figure=0)\n",
    "    \n",
    "    # Loop over the crossvalidation folds \n",
    "    for i in range(K):\n",
    "        r,b=fitfcn(D[ind!=i],y[ind!=i],xname,b_init=b_all,figure=0)\n",
    "        yp[ind==i]=predictfcn(b,D[ind==i],xname)\n",
    "    LLcv = sum(y*np.log(yp)+(1-y)*np.log(1-yp))\n",
    "    return LLcv,LL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood difference between Smoke and intercept model:1.8248\n",
      "Bayes Factor: 6.201\n"
     ]
    }
   ],
   "source": [
    "llcv0,ll0=KfoldCVlogisticReg(D,D.complication,[])\n",
    "llcv1,ll1=KfoldCVlogisticReg(D,D.complication,['smokeDummy'])\n",
    "print(f'Log-likelihood difference between Smoke and intercept model:{llcv1-llcv0:.4f}')\n",
    "print(f'Bayes Factor: {np.exp(llcv1-llcv0):.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is positive evidence that smoking leads to increased chance of complications in the first 3 month.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.3:\n",
    "Compare the model that uses only intercept, smoking as explanatory variable to one that uses: \n",
    "\n",
    " * intercept, smoking, weight \n",
    " * intercept, smoking, age \n",
    " * intercept, smoking, weight, age \n",
    " \n",
    "Report the cross-validated Log-likelihood for each model. Which one is the best model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding weight to baseline mode: 1.751\n"
     ]
    }
   ],
   "source": [
    "llcv2,ll2=KfoldCVlogisticReg(D,D.complication,['smokeDummy','weight'])\n",
    "print(f'Adding weight to baseline mode: {llcv2-llcv1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding age to baseline mode: -0.976\n"
     ]
    }
   ],
   "source": [
    "llcv3,ll3=KfoldCVlogisticReg(D,D.complication,['smokeDummy','age'])\n",
    "print(f'Adding age to baseline mode: {llcv3-llcv1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding age and weight to baseline mode: 0.699\n"
     ]
    }
   ],
   "source": [
    "llcv4,ll4=KfoldCVlogisticReg(D,D.complication,['smokeDummy','weight','age'])\n",
    "print(f'Adding age and weight to baseline mode: {llcv4-llcv1:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> According to the crossvalidated likelihood, the model with smoking, weight is the best model. However, there is no positive evidence (in terms of a Bayes factor) that adding age into the model increases the prediction. The most complex model (smoking, weight, age) is not better than the model with only smoking and weight. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.4 : \n",
    "In the model (['smokeDummy','weight']), how do each of the explanatory variables contribute to the chance of complication? That is, for each variable, would an increase an the variable lead to an increased or decreased probability of a complication? \n",
    "\n",
    "What reduction in birth weight causes the same amount of risk of complication as having a smoking mother?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 3.764\n",
      "Smoke: 0.611\n",
      "Weight: -0.719\n"
     ]
    }
   ],
   "source": [
    "ll,b=logisticRegFit(D,D.complication,['smokeDummy','weight'])\n",
    "print(f'Intercept: {b[0]:.3f}')\n",
    "print(f'Smoke: {b[1]:.3f}')\n",
    "print(f'Weight: {b[2]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of slopes smoking / pounds: -0.850\n"
     ]
    }
   ],
   "source": [
    "print(f'Ratio of slopes smoking / pounds: {b[1]/b[2]:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Smoking increases the chances of complication. Lower weight also increases the chances of complications. Smoking adds about as much risk as a lower birthweight of 0.85 pounds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
